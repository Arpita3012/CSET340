{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOL5aDl6u06YuyD5LJn0T6R",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Arpita3012/CSET340/blob/main/apache_jira_scraper.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p apache-jira-scraper/data/raw apache-jira-scraper/data/processed apache-jira-scraper/logs\n",
        "%cd apache-jira-scraper\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h8Qsbwx-u87y",
        "outputId": "c20c7598-8f60-45ef-8fdc-032a575d8bf7"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/apache-jira-scraper\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile requirements.txt\n",
        "requests\n",
        "tqdm\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cgjQmvmLv-EK",
        "outputId": "8cd8f31e-474c-48ba-8f6e-84f12b82fd55"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing requirements.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile utils.py\n",
        "import json\n",
        "import datetime\n",
        "\n",
        "def save_checkpoint(project, value, filename=\"checkpoint.json\"):\n",
        "    try:\n",
        "        with open(filename, \"r\") as f:\n",
        "            data = json.load(f)\n",
        "    except FileNotFoundError:\n",
        "        data = {}\n",
        "    data[project] = value\n",
        "    with open(filename, \"w\") as f:\n",
        "        json.dump(data, f)\n",
        "\n",
        "def load_checkpoint(filename=\"checkpoint.json\"):\n",
        "    try:\n",
        "        with open(filename, \"r\") as f:\n",
        "            return json.load(f)\n",
        "    except FileNotFoundError:\n",
        "        return {}\n",
        "\n",
        "def log_message(msg, logfile=\"logs/scraper.log\"):\n",
        "    timestamp = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "    with open(logfile, \"a\") as f:\n",
        "        f.write(f\"[{timestamp}] {msg}\\n\")\n",
        "    print(msg)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iPqunY6ewGhH",
        "outputId": "7129a9cc-3267-4939-fabc-df209cff17b0"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing utils.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python utils.py\n"
      ],
      "metadata": {
        "id": "2lm3NewSx9rJ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile scraper.py\n",
        "import requests\n",
        "import json\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "from utils import save_checkpoint, load_checkpoint, log_message\n",
        "\n",
        "BASE_URL = \"https://issues.apache.org/jira/rest/api/2/search\"\n",
        "PROJECTS = [\"ACCUMULO\", \"ACE\", \"ARTEMIS\"]  # Updated project list âœ…\n",
        "PAGE_SIZE = 500\n",
        "MAX_RETRIES = 3\n",
        "\n",
        "def fetch_issues(project, start_at):\n",
        "    params = {\n",
        "        \"jql\": f\"project={project}\",\n",
        "        \"maxResults\": PAGE_SIZE,\n",
        "        \"startAt\": start_at\n",
        "    }\n",
        "\n",
        "    for attempt in range(MAX_RETRIES):\n",
        "        try:\n",
        "            response = requests.get(BASE_URL, params=params, timeout=15)\n",
        "            if response.status_code == 200:\n",
        "                return response.json()\n",
        "            elif response.status_code == 429:\n",
        "                log_message(\"Rate limit hit. Sleeping 30s...\")\n",
        "                time.sleep(30)\n",
        "            elif 500 <= response.status_code < 600:\n",
        "                log_message(f\"Server error {response.status_code}. Retry {attempt+1}/{MAX_RETRIES}\")\n",
        "                time.sleep(5)\n",
        "            else:\n",
        "                log_message(f\"Unexpected status {response.status_code}\")\n",
        "                break\n",
        "        except requests.exceptions.RequestException as e:\n",
        "            log_message(f\"Request failed: {e}\")\n",
        "            time.sleep(5)\n",
        "    return None\n",
        "\n",
        "\n",
        "def scrape_project(project):\n",
        "    checkpoint = load_checkpoint()\n",
        "    start_at = checkpoint.get(project, 0)\n",
        "    all_issues = []\n",
        "\n",
        "    while True:\n",
        "        data = fetch_issues(project, start_at)\n",
        "        if not data or \"issues\" not in data:\n",
        "            break\n",
        "\n",
        "        issues = data[\"issues\"]\n",
        "        if not issues:\n",
        "            break\n",
        "\n",
        "        for issue in issues:\n",
        "            all_issues.append(issue)\n",
        "\n",
        "        with open(f\"data/raw/{project}.json\", \"a\", encoding=\"utf-8\") as f:\n",
        "            for issue in issues:\n",
        "                json.dump(issue, f)\n",
        "                f.write(\"\\n\")\n",
        "\n",
        "        start_at += len(issues)\n",
        "        save_checkpoint(project, start_at)\n",
        "        log_message(f\"{project}: fetched {len(issues)} issues, total so far {start_at}\")\n",
        "\n",
        "        if len(issues) < PAGE_SIZE:\n",
        "            break\n",
        "\n",
        "        time.sleep(1)\n",
        "\n",
        "    log_message(f\"{project}: completed scraping {start_at} issues.\")\n",
        "    return all_issues\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    for project in PROJECTS:\n",
        "        log_message(f\"Starting scraping for {project}\")\n",
        "        scrape_project(project)\n",
        "        log_message(f\"Finished scraping {project}\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DloNXDqcwQj3",
        "outputId": "f62cabdd-6fc9-46e0-e4f6-733d7164bc3a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting scraper.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python scraper.py\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-8LzwkNvyDo2",
        "outputId": "cbd0b12d-ae95-4738-94fb-2b9f92975304"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting scraping for ACCUMULO\n",
            "ACCUMULO: completed scraping 4745 issues.\n",
            "Finished scraping ACCUMULO\n",
            "\n",
            "Starting scraping for ACE\n",
            "ACE: fetched 389 issues, total so far 539\n",
            "ACE: completed scraping 539 issues.\n",
            "Finished scraping ACE\n",
            "\n",
            "Starting scraping for ARTEMIS\n",
            "ARTEMIS: fetched 500 issues, total so far 500\n",
            "ARTEMIS: fetched 500 issues, total so far 1000\n",
            "ARTEMIS: fetched 500 issues, total so far 1500\n",
            "ARTEMIS: fetched 500 issues, total so far 2000\n",
            "ARTEMIS: fetched 500 issues, total so far 2500\n",
            "ARTEMIS: fetched 500 issues, total so far 3000\n",
            "ARTEMIS: fetched 500 issues, total so far 3500\n",
            "ARTEMIS: fetched 500 issues, total so far 4000\n",
            "ARTEMIS: fetched 500 issues, total so far 4500\n",
            "ARTEMIS: fetched 500 issues, total so far 5000\n",
            "ARTEMIS: fetched 500 issues, total so far 5500\n",
            "ARTEMIS: fetched 118 issues, total so far 5618\n",
            "ARTEMIS: completed scraping 5618 issues.\n",
            "Finished scraping ARTEMIS\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile transform.py\n",
        "import json\n",
        "import os\n",
        "\n",
        "RAW_DIR = \"data/raw\"\n",
        "PROCESSED_FILE = \"data/processed/apache_issues.jsonl\"\n",
        "\n",
        "def extract_text(issue):\n",
        "    fields = issue.get(\"fields\", {})\n",
        "    return {\n",
        "        \"project\": fields.get(\"project\", {}).get(\"key\"),\n",
        "        \"issue_key\": issue.get(\"key\"),\n",
        "        \"title\": fields.get(\"summary\"),\n",
        "        \"description\": fields.get(\"description\"),\n",
        "        \"status\": fields.get(\"status\", {}).get(\"name\"),\n",
        "        \"assignee\": fields.get(\"assignee\", {}).get(\"displayName\") if fields.get(\"assignee\") else None,\n",
        "        \"reporter\": fields.get(\"reporter\", {}).get(\"displayName\") if fields.get(\"reporter\") else None,\n",
        "        \"priority\": fields.get(\"priority\", {}).get(\"name\") if fields.get(\"priority\") else None,\n",
        "        \"labels\": fields.get(\"labels\"),\n",
        "        \"created\": fields.get(\"created\"),\n",
        "        \"updated\": fields.get(\"updated\"),\n",
        "        \"comments\": \"\\n\".join(\n",
        "            c.get(\"body\", \"\") for c in (fields.get(\"comment\", {}).get(\"comments\", []))\n",
        "        ),\n",
        "        \"task\": \"summarization\"\n",
        "    }\n",
        "\n",
        "def transform_to_jsonl():\n",
        "    with open(PROCESSED_FILE, \"w\", encoding=\"utf-8\") as out_f:\n",
        "        for raw_file in os.listdir(RAW_DIR):\n",
        "            path = os.path.join(RAW_DIR, raw_file)\n",
        "            with open(path, \"r\", encoding=\"utf-8\") as f:\n",
        "                for line in f:\n",
        "                    issue = json.loads(line)\n",
        "                    transformed = extract_text(issue)\n",
        "                    json.dump(transformed, out_f)\n",
        "                    out_f.write(\"\\n\")\n",
        "    print(\"âœ… Transformation complete â†’ data/processed/apache_issues.jsonl\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    transform_to_jsonl()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p39u9Moay5Bs",
        "outputId": "fe748071-d380-43c5-e30f-81a3480db768"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing transform.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python transform.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PVunYr9Szavo",
        "outputId": "221cf0b9-06d4-477b-a48d-036941668d64"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Transformation complete â†’ data/processed/apache_issues.jsonl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!head -n 5 data/processed/apache_issues.jsonl\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IE7qn8EbzeyY",
        "outputId": "accacb31-7cb4-4409-cefd-0b2f05b18c3f"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"project\": \"ACE\", \"issue_key\": \"ACE-635\", \"title\": \"TV Channel Duke vs Virginia Tech Live College basketball 2018 Watch Online\", \"description\": \"TV Channel Duke vs Virginia Tech Live College basketball 2018 Watch\\r\\n\\r\\nCLICK HERE >>>> [http://livetv24.org/college-basketball|http://livetv24.org/college-basketball]\\r\\n\\r\\nMarvin Bagley's status uncertain for Duke's game against Virginia Tech. Duke associate head coach Jeff Capel III said Monday that he did not have an update yet on freshman forward Marvin Bagley III's status for Wednesday's game against Virginia Tech. Prolific\\r\\n\\r\\nDuke poses challenges for Virginia Tech. Duke vs. Virginia Tech odds: Picks from unbiased computer model on 15-7 run, The Virginia Tech Hokies visit the Duke Blue Devils at Cameron Indoor Stadium on Wednesday night at 7 p.m. ET. The Blue Devils are favored by 11 points, unchanged from the opening line. The Over-Under, or total number of points\\r\\n\\r\\nVegas thinks will be scored, is 162, down half-a-point from the open. \\r\\n Duke vs Virginia Tech Live Stream - Batmanstreamcom\\r\\n Watch Duke vs Virginia Tech Live Stream. Watch this game live and online for free. NCAA College Basketball.\\r\\n\\r\\nWatch Duke vs Virginia Tech Live Stream College Basketball\\r\\n Watch Duke vs Virginia Tech Live Stream NCAA College Basketball Feb 14 2018 Watch Virginia Tech vs Duke live stream NCAAM Duke vs Virginia Tech live...\\r\\n Virginia Tech vs Duke Live Stream: Watch Hokies vs Blue Devils\\r\\n\\r\\nThe Virginia Tech Hokies and Duke Blue Devils face each other this week in a pivotal ACC Coastal game. Here is all the live stream information.The 19th ranked Virginia Tech Hokies visit the Duke Blue Devils this week looking to continue to their quest to the ACC Championship game. At 6-2 on the se...\\r\\n\\r\\nDuke vs. Virginia Tech 2017 live stream: Start time, TV channel\\r\\n Oct 28, 2017 - After coming off a victory over North Carolina, the Virginia Tech Hokies will host the desperate Duke Blue Devils on Saturday. Kickoff is set for 7:20 p.m. on the ACC Network (live stream). The Blue Devils are coming off of their fourth straight loss, and they will need to put together the missing pieces in order ...\\r\\n\\r\\nLive(TV) Duke vs Georgia Tech 2018 Live Stream NCAA College\\r\\n \\\"Duke vs Georgia Tech Live\\\" Stream NCAAB Online TV Coverage Watch Georgia Tech vs Duke Live Stream. Watch this game live and online for free. NCAA College Basketball. Duke's Marvin Bagley ruled out fo.\\r\\n\\r\\nHow to watch Duke vs. Virginia Tech: TV, time, live stream, matchups\\r\\n Everything you need to prepare for Duke-Virginia Tech.\\r\\n Duke Blue Devils - NCAA Basketball - CBSSportscom\\r\\n\\r\\nFebruary 14, 2018 1:21 pm. Duke vs. Virginia Tech odds: Picks from unbiased computer model on 15-7 run. Our advanced computer model simulated Wednesday's Virginia Tech vs. Duke game 10,000 times. | February 14, 2018 11:47 am. TDD Podcast: Duke's Defense, Youth, and Focus. Plus, our coverage of Signing Day.\\r\\n\\r\\nVirginia Tech Hokies - NCAA College Football - CBSSportscom\\r\\n Virginia Tech Hokies college football news, scores, stats and standings provided by CBSSports.com.\\r\\n\\r\\nWatch Duke vs Virginia Tech online: Live stream, game time, TV | SIcom\\r\\n The No. 23 Duke Blue Devils (5-1, 2-0 ACC) will go on the road to face the Virginia Tech Hokies (3-4, 1-2 ACC) on Saturday at Lane Stadium. Duke is coming off a bye week after defeating Army 44-3 on Oct. 10. Quarterback Thomas Sirk recorded 197 passing yards and one touchdown, while Parker ...\\r\\n\\r\\nVirginia Tech Hokies College Basketball - Virginia Tech News, Scores \\r\\n ESPN Stats and Information. By beating 2 Virginia on Saturday on the Cavaliers' home court, the Hokies secured their first road win against a top-5 team since January 21, 2009 when they beat then No. 1 Wake Forest. Virginia Tech has now won 3 of its last 4 games vs top-5 opponents.\\r\\n\\r\\nVirginia Tech Hokies College Basketball - Virginia Tech News, Scores \\r\\n ESPN Stats and Information. By beating 2 Virginia on Saturday on the Cavaliers' home court, the Hokies secured their first road win against a top-5 team since January 21, 2009 when they beat then No. 1 Wake Forest. Virginia Tech has now won 3 of its last 4 games vs top-5 opponents. share. 3d ...\\r\\n\\r\\nDuke Blue Devils College Basketball - Duke News, Scores, Stats\\r\\n Get the latest Duke Blue Devils news, scores, stats, standings, rumors, and more from ESPN. ... Shouldn't the Spartans take over the top spot after they beat Purdue and after Villanova and Virginia lost? Not so fast. ... Marvin Bagley III has been ruled out for tonight's game against Georgia Tech due to a mild right knee sprain.\\r\\n\\r\\nVirginia Tech IMG Sports Network | Free Internet Radio | TuneIn\\r\\n Virginia Tech IMG Sports Network - US - Listen to free internet radio, sports, music, news, talk and podcasts. Stream live events, live play-by-play NFL, MLB, NBA, NHL, college football, NCAA basketball, and Premier League matches. CNN, MSNBC, Fox News, ESPN, BBC, NPR.\\r\\n\\r\\nVirginia Tech Basketball tickets, Virginia Tech Hokies Basketball\\r\\n Virginia Tech Basketball tickets - Buy and sell Virginia Tech Basketball tickets and other NCAA Basketball tickets on StubHub! Buy your Virginia Tech Hokies Basketball Ticket today.\", \"status\": \"Open\", \"assignee\": null, \"reporter\": \"Marie M. Greer\", \"priority\": \"Major\", \"labels\": [], \"created\": \"2018-02-14T23:30:40.000+0000\", \"updated\": \"2018-02-14T23:31:14.000+0000\", \"comments\": \"\", \"task\": \"summarization\"}\n",
            "{\"project\": \"ACE\", \"issue_key\": \"ACE-634\", \"title\": \"Sort tag editor entries \", \"description\": \"When the list of tags gets bigger they become hard to find sorting them alphabetically on key would make this better.\", \"status\": \"Open\", \"assignee\": null, \"reporter\": \"Bram Pouwelse\", \"priority\": \"Trivial\", \"labels\": [], \"created\": \"2017-11-01T20:09:44.000+0000\", \"updated\": \"2017-11-01T20:12:28.000+0000\", \"comments\": \"\", \"task\": \"summarization\"}\n",
            "{\"project\": \"ACE\", \"issue_key\": \"ACE-633\", \"title\": \"NPE in exception handling code after unexpected response from audit log query\", \"description\": \"Found this one debugging ACE-632 same reproduction steps can be used. \\r\\n\\r\\n{code}\\r\\n2017.11.01 20:07:50 WARNING - Bundle: org.apache.ace.agent - Exception - java.lang.NullPointerException\\r\\n\\tat org.apache.ace.agent.impl.ConnectionUtil.flushStream(ConnectionUtil.java:167)\\r\\n\\tat org.apache.ace.agent.impl.ConnectionUtil.handleIOException(ConnectionUtil.java:112)\\r\\n\\tat org.apache.ace.agent.impl.FeedbackChannelImpl.sendFeedback(FeedbackChannelImpl.java:109)\\r\\n\\tat org.apache.ace.agent.impl.DefaultController.runFeedback(DefaultController.java:643)\\r\\n\\tat org.apache.ace.agent.impl.DefaultController.run(DefaultController.java:462)\\r\\n\\tat org.apache.ace.agent.impl.AgentContextImpl$1.run(AgentContextImpl.java:252)\\r\\n\\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\\r\\n\\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\\r\\n\\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\\r\\n\\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\\r\\n\\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\\r\\n\\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\\r\\n\\tat java.lang.Thread.run(Thread.java:745)\\r\\n{code}\", \"status\": \"Open\", \"assignee\": null, \"reporter\": \"Bram Pouwelse\", \"priority\": \"Trivial\", \"labels\": [], \"created\": \"2017-11-01T19:19:28.000+0000\", \"updated\": \"2017-11-01T19:19:28.000+0000\", \"comments\": \"\", \"task\": \"summarization\"}\n",
            "{\"project\": \"ACE\", \"issue_key\": \"ACE-632\", \"title\": \"DefaultController run loop halts on a runtime exception\", \"description\": \"The run loop in the default controller stops on a RuntimeException without leaving a trace in the logs. \\r\\n\\r\\n*Reproduce: *\\r\\nHave a mistake in your discovery configuration and put something like http://localhost:8080/ace instead of http://localhost:8080/ in there. \\r\\n\\r\\nThis will cause a NPE when trying to sync the audit log which will make the agent die after only outputting something like :\\r\\n\\r\\n{code}\\r\\n2017.11.01 20:07:55 DEBUG - Bundle: org.apache.ace.agent - Synchronizing feedback channels: [auditlog]\\r\\n2017.11.01 20:07:55 DEBUG - Bundle: org.apache.ace.agent - Controller syncing\\r\\n{code}\\r\\n\\r\\nAfter this message the logs go silent... and the agent stopped working\", \"status\": \"Open\", \"assignee\": null, \"reporter\": \"Bram Pouwelse\", \"priority\": \"Major\", \"labels\": [], \"created\": \"2017-11-01T19:16:12.000+0000\", \"updated\": \"2017-11-01T19:16:12.000+0000\", \"comments\": \"\", \"task\": \"summarization\"}\n",
            "{\"project\": \"ACE\", \"issue_key\": \"ACE-631\", \"title\": \"Have some way to be able to recover from lost target state on the server\", \"description\": \"After a data corruption / loss on the server you are \\\"forced\\\" to clear a target as well as in such a case the current target deployment version is (likely to be) higher than the next available version.\\r\\n\\r\\nIf this happens I think it makes sense to require some user intervention to get updates going again but we do need some way to bump deployment version on the server to installed + 1\\r\\n\\r\\n(and an error marker in the target list would be nice)\", \"status\": \"Open\", \"assignee\": null, \"reporter\": \"Bram Pouwelse\", \"priority\": \"Major\", \"labels\": [], \"created\": \"2017-11-01T18:52:09.000+0000\", \"updated\": \"2017-11-01T18:52:09.000+0000\", \"comments\": \"\", \"task\": \"summarization\"}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wc -l data/processed/apache_issues.jsonl\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tp5pLUmb0XEF",
        "outputId": "28240635-edfd-4f0e-c5fa-a12d23138aef"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10902 data/processed/apache_issues.jsonl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "\n",
        "# Input and output file paths\n",
        "jsonl_path = \"data/processed/apache_issues.jsonl\"\n",
        "csv_path = \"data/processed/apache_issues.csv\"\n",
        "\n",
        "# Read JSONL and convert\n",
        "rows = []\n",
        "with open(jsonl_path, \"r\", encoding=\"utf-8\") as f:\n",
        "    for line in f:\n",
        "        rows.append(json.loads(line))\n",
        "\n",
        "# Convert to DataFrame and save as CSV\n",
        "df = pd.DataFrame(rows)\n",
        "df.to_csv(csv_path, index=False)\n",
        "\n",
        "print(\"âœ… Converted to CSV â†’\", csv_path)\n",
        "print(\"ðŸ“Š Total records:\", len(df))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-4EMCEc30tPZ",
        "outputId": "efbc835b-ae01-44e9-8da9-a678fe87031c"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Converted to CSV â†’ data/processed/apache_issues.csv\n",
            "ðŸ“Š Total records: 10902\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "23kQfEud1I7k"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}